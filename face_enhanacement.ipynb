{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/girinath18/CodeFormer/blob/Remastered/face_enhanacement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "%cd /content\n",
        "!rm -rf /content/CodeFormer\n",
        "!git clone https://github.com/sczhou/CodeFormer.git\n",
        "%cd /content/CodeFormer\n",
        "!pip install -r /content/CodeFormer/requirements.txt\n",
        "# Install basicsr\n",
        "!python /content/CodeFormer/basicsr/setup.py develop\n",
        "# Download the pre-trained model\n",
        "!python /content/CodeFormer/scripts/download_pretrained_models.py facelib\n",
        "!python /content/CodeFormer/scripts/download_pretrained_models.py CodeFormer\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "0iN5zS044nZB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAyiISUI4bhZ",
        "outputId": "903e0cfa-1c58-4777-ef15-b24dff5f4791"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n",
            "The folder exists.\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)\n",
        "drive_input_folder = \"/content/gdrive/MyDrive/upload\"\n",
        "if os.path.exists(drive_input_folder):\n",
        "    print(\"The folder exists.\")\n",
        "else:\n",
        "    os.mkdir(drive_input_folder)\n",
        "    print(f\"Creating {drive_input_folder} folder\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Utils { display-mode: \"form\" }\n",
        "\n",
        "\n",
        "# Visualization function\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil\n",
        "def display(img1, img2):\n",
        "  fig = plt.figure(figsize=(25, 10))\n",
        "  ax1 = fig.add_subplot(1, 2, 1)\n",
        "  plt.title('Input', fontsize=16)\n",
        "  ax1.axis('off')\n",
        "  ax2 = fig.add_subplot(1, 2, 2)\n",
        "  plt.title('CodeFormer', fontsize=16)\n",
        "  ax2.axis('off')\n",
        "  ax1.imshow(img1)\n",
        "  ax2.imshow(img2)\n",
        "def imread(img_path):\n",
        "  img = cv2.imread(img_path)\n",
        "  img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "  return img\n",
        "\n",
        "upload_folder = ('/content/input')\n",
        "if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "os.mkdir(upload_folder)\n",
        "if os.path.exists(\"/content/output\"):\n",
        "  shutil.rmtree(\"/content/output\")\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "CKHQWctq8n47"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import os\n",
        "import shutil\n",
        "from google.colab import drive\n",
        "import os\n",
        "from google.colab import files\n",
        "keep_images = False\n",
        "upload_folder = ('/content/input')\n",
        "%cd /content/CodeFormer\n",
        "\n",
        "if keep_images:\n",
        "  pass\n",
        "else:\n",
        "  if os.path.isdir(upload_folder):\n",
        "    shutil.rmtree(upload_folder)\n",
        "  os.mkdir(upload_folder)\n",
        "\n",
        "\n",
        "def image_from_drive():\n",
        "  drive.mount('/content/gdrive',force_remount=True)\n",
        "  drive_input_folder = \"/content/input\"\n",
        "  if os.path.exists(drive_input_folder):\n",
        "      print(\"The folder exists.\")\n",
        "  else:\n",
        "      os.mkdir(drive_input_folder)\n",
        "  image_extensions = ['.jpg', '.jpeg', '.png']\n",
        "  for filename in os.listdir(drive_input_folder):\n",
        "    _, extension = os.path.splitext(filename)\n",
        "    if extension.lower() in image_extensions:\n",
        "      drive_image_path=os.path.join(drive_input_folder,filename)\n",
        "      shutil.copy(drive_image_path,upload_folder)\n",
        "def image_from_device():\n",
        "  uploaded = files.upload()\n",
        "  for filename in uploaded.keys():\n",
        "    dst_path = os.path.join(upload_folder, filename)\n",
        "    print(f'move {filename} to {dst_path}')\n",
        "    shutil.move(filename, dst_path)\n",
        "\n",
        "upload_from = \"local device\"\n",
        "if upload_from == \"google drive\":\n",
        "  image_from_drive()\n",
        "if upload_from == \"local device\":\n",
        "  image_from_device()\n",
        "clear_output()\n",
        "file_count = len(os.listdir(upload_folder))\n",
        "if file_count >= 1:\n",
        "    print(\"Run next cell\")\n",
        "else:\n",
        "    print(\"Please upload an image.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "0Xf9RTaM5JOx",
        "outputId": "14d31bbd-c8be-4795-f555-5925da274dc7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/CodeFormer\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-be2127c8-16cf-4d33-8e4e-438fdcb90660\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-be2127c8-16cf-4d33-8e4e-438fdcb90660\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c0a71497f405>\u001b[0m in \u001b[0;36m<cell line: 42>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m   \u001b[0mimage_from_drive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mupload_from\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"local device\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m   \u001b[0mimage_from_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0mclear_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0mfile_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-2-c0a71497f405>\u001b[0m in \u001b[0;36mimage_from_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m       \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdrive_image_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mupload_folder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mimage_from_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m   \u001b[0muploaded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0muploaded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mdst_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mupload_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36mupload\u001b[0;34m()\u001b[0m\n\u001b[1;32m     67\u001b[0m   \"\"\"\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m   \u001b[0muploaded_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_upload_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m   \u001b[0;31m# Mapping from original filename to filename as saved locally.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m   \u001b[0mlocal_filenames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/files.py\u001b[0m in \u001b[0;36m_upload_files\u001b[0;34m(multiple)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m   \u001b[0;31m# First result is always an indication that the file picker has completed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m   result = _output.eval_js(\n\u001b[0m\u001b[1;32m    157\u001b[0m       'google.colab._files._uploadFiles(\"{input_id}\", \"{output_id}\")'.format(\n\u001b[1;32m    158\u001b[0m           \u001b[0minput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_id\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/output/_js.py\u001b[0m in \u001b[0;36meval_js\u001b[0;34m(script, ignore_result, timeout_sec)\u001b[0m\n\u001b[1;32m     38\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mignore_result\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     if (\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Inference the uploaded images\n",
        "%cd /content/CodeFormer\n",
        "\n",
        "CODEFORMER_FIDELITY = 0.7\n",
        "\n",
        "BACKGROUND_ENHANCE = True\n",
        "\n",
        "FACE_UPSAMPLE = True\n",
        "if BACKGROUND_ENHANCE:\n",
        "  if FACE_UPSAMPLE:\n",
        "    !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload --bg_upsampler realesrgan --face_upsample\n",
        "  else:\n",
        "    !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload --bg_upsampler realesrgan\n",
        "else:\n",
        "  !python inference_codeformer.py -w $CODEFORMER_FIDELITY --input_path inputs/user_upload\n",
        "clear_output()\n",
        "print(f\"All results are saved in /content/output{CODEFORMER_FIDELITY}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HCLQV1X5z_J",
        "outputId": "252127ac-a39a-417c-8167-d2c2865622fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All results are saved in /content/output0.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "7IW8DMCB_DgB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "save_a_copy_in_google_drive = True\n",
        "if save_a_copy_in_google_drive:\n",
        "  drive.mount('/content/gdrive',force_remount=True)\n",
        "  drive_save_path = '/content/gdrive/MyDrive/CodeFormer_Bulk_Upscale'\n",
        "  if os.path.exists(drive_save_path):\n",
        "    pass\n",
        "  else:\n",
        "    os.mkdir(drive_save_path)\n",
        "  clear_output()\n",
        "  print(f\"All images/zip file save at : {drive_save_path}\")\n",
        "\n",
        "import os\n",
        "import uuid\n",
        "from google.colab import files\n",
        "import shutil\n",
        "def download_single_images():\n",
        "  global CODEFORMER_FIDELITY\n",
        "  download_folder = '/content/download'\n",
        "  if os.path.exists(download_folder):\n",
        "      os.system(f'rm -rf {download_folder}')\n",
        "  os.makedirs(download_folder)\n",
        "  folder_path = f\"/content/CodeFormer/results/user_upload_{CODEFORMER_FIDELITY}/final_results\"\n",
        "  for filename in os.listdir(folder_path):\n",
        "      original_path = os.path.join(folder_path, filename)\n",
        "      name, extension = os.path.splitext(filename)\n",
        "      random_string = str(uuid.uuid4())[:8]\n",
        "      new_filename = f\"{name}_{random_string}{extension}\"\n",
        "      download_path = f\"/content/download/{new_filename}\"\n",
        "      if save_a_copy_in_google_drive:\n",
        "        drive_path=f\"{drive_save_path}/{new_filename}\"\n",
        "        shutil.copy(original_path, drive_path)\n",
        "      shutil.copy(original_path, download_path)\n",
        "\n",
        "      files.download(download_path)\n",
        "def download_zip():\n",
        "  global CODEFORMER_FIDELITY\n",
        "  random_string = str(uuid.uuid4())[:5]\n",
        "  zip_file_name=f\"results_{random_string}.zip\"\n",
        "  var1=os.system(f'zip -r {zip_file_name} results/user_upload_{CODEFORMER_FIDELITY}/final_results')\n",
        "  if save_a_copy_in_google_drive:\n",
        "    sour=f\"/content/CodeFormer/{zip_file_name}\"\n",
        "    dest=f\"{drive_save_path}/{zip_file_name}\"\n",
        "    shutil.copy(sour, dest)\n",
        "\n",
        "  files.download(zip_file_name)\n",
        "\n",
        "\n",
        "\n",
        "folder_path = f\"/content/CodeFormer/results/user_upload_{CODEFORMER_FIDELITY}/final_results\"\n",
        "image_extensions = ['.jpg', '.jpeg', '.png', '.gif', '.bmp']  # Add more extensions if needed\n",
        "contains_image = False\n",
        "for filename in os.listdir(folder_path):\n",
        "    _, extension = os.path.splitext(filename)\n",
        "    if extension.lower() in image_extensions:\n",
        "        contains_image = True\n",
        "        break\n",
        "download_format = \"zip\"\n",
        "  if download_format == \"single file\":\n",
        "    download_single_images()\n",
        "  if download_format == \"zip\":\n",
        "    download_zip()\n",
        "else:\n",
        "  print(f\"The folder '{folder_path}' does not contain any image files.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "bcdJm5FB8QFa",
        "outputId": "d7cbecde-3a20-497a-f531-a91de9ec96b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "unexpected indent (<ipython-input-5-10595a1c01dd>, line 58)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-5-10595a1c01dd>\"\u001b[0;36m, line \u001b[0;32m58\u001b[0m\n\u001b[0;31m    if download_format == \"single file\":\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **maded as the single script**"
      ],
      "metadata": {
        "id": "07E3WfwiArKW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# Visualization Function\n",
        "def display(img1, img2):\n",
        "    fig = plt.figure(figsize=(25, 10))\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    plt.title('Input', fontsize=16)\n",
        "    ax1.axis('off')\n",
        "    ax2 = fig.add_subplot(1, 2, 2)\n",
        "    plt.title('CodeFormer', fontsize=16)\n",
        "    ax2.axis('off')\n",
        "    ax1.imshow(img1)\n",
        "    ax2.imshow(img2)\n",
        "\n",
        "def imread(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Image file not found at {img_path}\")\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "# Paths\n",
        "input_folder = '/content/input'\n",
        "output_folder = '/content/output_bots'\n",
        "codeformer_path = '/content/CodeFormer'\n",
        "\n",
        "# Clean up previous runs\n",
        "if os.path.isdir(input_folder):\n",
        "    shutil.rmtree(input_folder)\n",
        "os.mkdir(input_folder)\n",
        "if os.path.exists(output_folder):\n",
        "    shutil.rmtree(output_folder)\n",
        "os.mkdir(output_folder)\n",
        "\n",
        "# Image Upload\n",
        "def image_from_device():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(input_folder, filename)\n",
        "        print(f'Move {filename} to {dst_path}')\n",
        "        shutil.move(filename, dst_path)\n",
        "\n",
        "# Execute Image Upload\n",
        "image_from_device()\n",
        "clear_output()\n",
        "file_count = len(os.listdir(input_folder))\n",
        "if file_count >= 1:\n",
        "    print(\"Run next cell\")\n",
        "else:\n",
        "    print(\"Please upload an image.\")\n",
        "\n",
        "# Inference the uploaded images\n",
        "os.chdir(codeformer_path)\n",
        "\n",
        "CODEFORMER_FIDELITY = 0.7\n",
        "BACKGROUND_ENHANCE = True\n",
        "FACE_UPSAMPLE = True\n",
        "\n",
        "# Running the inference and saving outputs in specified output folder\n",
        "command = f'python inference_codeformer.py -w {CODEFORMER_FIDELITY} --input_path {input_folder} --output_path {output_folder}'\n",
        "if BACKGROUND_ENHANCE:\n",
        "    command += ' --bg_upsampler realesrgan'\n",
        "if FACE_UPSAMPLE:\n",
        "    command += ' --face_upsample'\n",
        "\n",
        "os.system(command)\n",
        "\n",
        "# Debugging information to verify the output\n",
        "print(f\"All results are saved in {output_folder}\")\n",
        "output_files = os.listdir(output_folder)\n",
        "print(f\"Files in output folder: {output_files}\")\n",
        "\n",
        "# Check if output folder contains any images\n",
        "if not output_files:\n",
        "    raise FileNotFoundError(f\"No output images found in {output_folder}\")\n",
        "\n",
        "# Display Results\n",
        "input_image_path = os.path.join(input_folder, os.listdir(input_folder)[0])\n",
        "output_image_path = os.path.join(output_folder, output_files[0])\n",
        "\n",
        "print(f\"Input image path: {input_image_path}\")\n",
        "print(f\"Output image path: {output_image_path}\")\n",
        "\n",
        "input_image = imread(input_image_path)\n",
        "output_image = imread(output_image_path)\n",
        "display(input_image, output_image)\n"
      ],
      "metadata": {
        "id": "g9BoeBF6AwuY",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "G8IGERN2m4oG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rcGq6lMIm4le"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def process_and_display_images(input_folder):\n",
        "    # Visualization Function\n",
        "    def display(img1, img2):\n",
        "        fig = plt.figure(figsize=(25, 10))\n",
        "        ax1 = fig.add_subplot(1, 2, 1)\n",
        "        plt.title('Input', fontsize=16)\n",
        "        ax1.axis('off')\n",
        "        ax2 = fig.add_subplot(1, 2, 2)\n",
        "        plt.title('CodeFormer', fontsize=16)\n",
        "        ax2.axis('off')\n",
        "        ax1.imshow(img1)\n",
        "        ax2.imshow(img2)\n",
        "\n",
        "    def imread(img_path):\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            raise FileNotFoundError(f\"Image file not found at {img_path}\")\n",
        "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "        return img\n",
        "\n",
        "    # Paths\n",
        "    output_folder = '/content/output_bots/'\n",
        "    codeformer_path = '/content/CodeFormer'\n",
        "\n",
        "    # Clean up previous runs\n",
        "    if os.path.exists(output_folder):\n",
        "        shutil.rmtree(output_folder)\n",
        "    os.mkdir(output_folder)\n",
        "\n",
        "    # Check if input folder contains any images\n",
        "    if not os.path.isdir(input_folder) or not os.listdir(input_folder):\n",
        "        print(\"The input folder is empty or does not exist. Please provide a valid input folder with images.\")\n",
        "        return\n",
        "\n",
        "    # Inference the uploaded images\n",
        "    os.chdir(codeformer_path)\n",
        "\n",
        "    CODEFORMER_FIDELITY = 0.7\n",
        "    BACKGROUND_ENHANCE = True\n",
        "    FACE_UPSAMPLE = True\n",
        "\n",
        "    # Running the inference and saving outputs in specified output folder\n",
        "    command = f'python inference_codeformer.py -w {CODEFORMER_FIDELITY} --input_path {input_folder} --output_path {output_folder} --final_only'\n",
        "    if BACKGROUND_ENHANCE:\n",
        "        command += ' --bg_upsampler realesrgan'\n",
        "    if FACE_UPSAMPLE:\n",
        "        command += ' --face_upsample'\n",
        "\n",
        "    print(f\"Running command: {command}\")\n",
        "    return_code = os.system(command)\n",
        "\n",
        "    if return_code != 0:\n",
        "        print(f\"Command failed with return code: {return_code}\")\n",
        "        print(\"Please check the command and try again.\")\n",
        "        return\n",
        "\n",
        "    # Check if output folder contains any images\n",
        "    output_files = os.listdir(output_folder)\n",
        "    if not output_files:\n",
        "        print(\"No output images found. Something went wrong.\")\n",
        "        return\n",
        "\n",
        "    # Display Results\n",
        "    input_image_path = os.path.join(input_folder, os.listdir(input_folder)[0])\n",
        "    output_image_path = os.path.join(output_folder, output_files[0])\n",
        "\n",
        "    input_image = imread(input_image_path)\n",
        "    output_image = imread(output_image_path)\n",
        "    display(input_image, output_image)\n",
        "\n",
        "# Example usage: Call the function with the input folder path\n",
        "input_folder_path = '/content/input/'\n",
        "process_and_display_images(input_folder_path)\n"
      ],
      "metadata": {
        "id": "QSiqzD7Bm6KO",
        "outputId": "ae5348ef-2c2f-4df6-aee9-c7540b083a3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running command: python inference_codeformer.py -w 0.7 --input_path /content/input/ --output_path /content/output_bots/ --final_only --bg_upsampler realesrgan --face_upsample\n",
            "Command failed with return code: 512\n",
            "Please check the command and try again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **inference_codeformer.py**"
      ],
      "metadata": {
        "id": "xDBgwVOdm5TO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import argparse\n",
        "import glob\n",
        "import torch\n",
        "from torchvision.transforms.functional import normalize\n",
        "from basicsr.utils import imwrite, img2tensor, tensor2img\n",
        "from basicsr.utils.download_util import load_file_from_url\n",
        "from basicsr.utils.misc import gpu_is_available, get_device\n",
        "from facelib.utils.face_restoration_helper import FaceRestoreHelper\n",
        "from facelib.utils.misc import is_gray\n",
        "\n",
        "from basicsr.utils.registry import ARCH_REGISTRY\n",
        "\n",
        "pretrain_model_url = {\n",
        "    'restoration': 'https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/codeformer.pth',\n",
        "}\n",
        "\n",
        "def set_realesrgan():\n",
        "    from basicsr.archs.rrdbnet_arch import RRDBNet\n",
        "    from basicsr.utils.realesrgan_utils import RealESRGANer\n",
        "\n",
        "    use_half = False\n",
        "    if torch.cuda.is_available(): # set False in CPU/MPS mode\n",
        "        no_half_gpu_list = ['1650', '1660'] # set False for GPUs that don't support f16\n",
        "        if not True in [gpu in torch.cuda.get_device_name(0) for gpu in no_half_gpu_list]:\n",
        "            use_half = True\n",
        "\n",
        "    model = RRDBNet(\n",
        "        num_in_ch=3,\n",
        "        num_out_ch=3,\n",
        "        num_feat=64,\n",
        "        num_block=23,\n",
        "        num_grow_ch=32,\n",
        "        scale=2,\n",
        "    )\n",
        "    upsampler = RealESRGANer(\n",
        "        scale=2,\n",
        "        model_path=\"https://github.com/sczhou/CodeFormer/releases/download/v0.1.0/RealESRGAN_x2plus.pth\",\n",
        "        model=model,\n",
        "        tile=args.bg_tile,\n",
        "        tile_pad=40,\n",
        "        pre_pad=0,\n",
        "        half=use_half\n",
        "    )\n",
        "\n",
        "    if not gpu_is_available():  # CPU\n",
        "        import warnings\n",
        "        warnings.warn('Running on CPU now! Make sure your PyTorch version matches your CUDA.'\n",
        "                        'The unoptimized RealESRGAN is slow on CPU. '\n",
        "                        'If you want to disable it, please remove `--bg_upsampler` and `--face_upsample` in command.',\n",
        "                        category=RuntimeWarning)\n",
        "    return upsampler\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    device = get_device()\n",
        "    parser = argparse.ArgumentParser()\n",
        "\n",
        "    parser.add_argument('-i', '--input_path', type=str, default='./inputs/whole_imgs',\n",
        "            help='Input image, video or folder. Default: inputs/whole_imgs')\n",
        "    parser.add_argument('-o', '--output_path', type=str, default=None,\n",
        "            help='Output folder. Default: results/<input_name>_<w>')\n",
        "    parser.add_argument('-w', '--fidelity_weight', type=float, default=0.5,\n",
        "            help='Balance the quality and fidelity. Default: 0.5')\n",
        "    parser.add_argument('-s', '--upscale', type=int, default=2,\n",
        "            help='The final upsampling scale of the image. Default: 2')\n",
        "    parser.add_argument('--has_aligned', action='store_true', help='Input are cropped and aligned faces. Default: False')\n",
        "    parser.add_argument('--only_center_face', action='store_true', help='Only restore the center face. Default: False')\n",
        "    parser.add_argument('--draw_box', action='store_true', help='Draw the bounding box for the detected faces. Default: False')\n",
        "    # large det_model: 'YOLOv5l', 'retinaface_resnet50'\n",
        "    # small det_model: 'YOLOv5n', 'retinaface_mobile0.25'\n",
        "    parser.add_argument('--detection_model', type=str, default='retinaface_resnet50',\n",
        "            help='Face detector. Optional: retinaface_resnet50, retinaface_mobile0.25, YOLOv5l, YOLOv5n, dlib. \\\n",
        "                Default: retinaface_resnet50')\n",
        "    parser.add_argument('--bg_upsampler', type=str, default='None', help='Background upsampler. Optional: realesrgan')\n",
        "    parser.add_argument('--face_upsample', action='store_true', help='Face upsampler after enhancement. Default: False')\n",
        "    parser.add_argument('--bg_tile', type=int, default=400, help='Tile size for background sampler. Default: 400')\n",
        "    parser.add_argument('--suffix', type=str, default=None, help='Suffix of the restored faces. Default: None')\n",
        "    parser.add_argument('--save_video_fps', type=float, default=None, help='Frame rate for saving video. Default: None')\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    # ------------------------ input & output ------------------------\n",
        "    w = args.fidelity_weight\n",
        "    input_video = False\n",
        "    if args.input_path.endswith(('jpg', 'jpeg', 'png', 'JPG', 'JPEG', 'PNG')): # input single img path\n",
        "        input_img_list = [args.input_path]\n",
        "        result_root = f'results/test_img_{w}'\n",
        "    elif args.input_path.endswith(('mp4', 'mov', 'avi', 'MP4', 'MOV', 'AVI')): # input video path\n",
        "        from basicsr.utils.video_util import VideoReader, VideoWriter\n",
        "        input_img_list = []\n",
        "        vidreader = VideoReader(args.input_path)\n",
        "        image = vidreader.get_frame()\n",
        "        while image is not None:\n",
        "            input_img_list.append(image)\n",
        "            image = vidreader.get_frame()\n",
        "        audio = vidreader.get_audio()\n",
        "        fps = vidreader.get_fps() if args.save_video_fps is None else args.save_video_fps\n",
        "        video_name = os.path.basename(args.input_path)[:-4]\n",
        "        result_root = f'results/{video_name}_{w}'\n",
        "        input_video = True\n",
        "        vidreader.close()\n",
        "    else: # input img folder\n",
        "        if args.input_path.endswith('/'):  # solve when path ends with /\n",
        "            args.input_path = args.input_path[:-1]\n",
        "        # scan all the jpg and png images\n",
        "        input_img_list = sorted(glob.glob(os.path.join(args.input_path, '*.[jpJP][pnPN]*[gG]')))\n",
        "        result_root = f'results/{os.path.basename(args.input_path)}_{w}'\n",
        "\n",
        "    if not args.output_path is None: # set output path\n",
        "        result_root = args.output_path\n",
        "\n",
        "    test_img_num = len(input_img_list)\n",
        "    if test_img_num == 0:\n",
        "        raise FileNotFoundError('No input image/video is found...\\n'\n",
        "            '\\tNote that --input_path for video should end with .mp4|.mov|.avi')\n",
        "\n",
        "    # ------------------ set up background upsampler ------------------\n",
        "    if args.bg_upsampler == 'realesrgan':\n",
        "        bg_upsampler = set_realesrgan()\n",
        "    else:\n",
        "        bg_upsampler = None\n",
        "\n",
        "    # ------------------ set up face upsampler ------------------\n",
        "    if args.face_upsample:\n",
        "        if bg_upsampler is not None:\n",
        "            face_upsampler = bg_upsampler\n",
        "        else:\n",
        "            face_upsampler = set_realesrgan()\n",
        "    else:\n",
        "        face_upsampler = None\n",
        "\n",
        "    # ------------------ set up CodeFormer restorer -------------------\n",
        "    net = ARCH_REGISTRY.get('CodeFormer')(dim_embd=512, codebook_size=1024, n_head=8, n_layers=9,\n",
        "                                            connect_list=['32', '64', '128', '256']).to(device)\n",
        "\n",
        "    # ckpt_path = 'weights/CodeFormer/codeformer.pth'\n",
        "    ckpt_path = load_file_from_url(url=pretrain_model_url['restoration'],\n",
        "                                    model_dir='weights/CodeFormer', progress=True, file_name=None)\n",
        "    checkpoint = torch.load(ckpt_path)['params_ema']\n",
        "    net.load_state_dict(checkpoint)\n",
        "    net.eval()\n",
        "\n",
        "    # ------------------ set up FaceRestoreHelper -------------------\n",
        "    # large det_model: 'YOLOv5l', 'retinaface_resnet50'\n",
        "    # small det_model: 'YOLOv5n', 'retinaface_mobile0.25'\n",
        "    if not args.has_aligned:\n",
        "        print(f'Face detection model: {args.detection_model}')\n",
        "    if bg_upsampler is not None:\n",
        "        print(f'Background upsampling: True, Face upsampling: {args.face_upsample}')\n",
        "    else:\n",
        "        print(f'Background upsampling: False, Face upsampling: {args.face_upsample}')\n",
        "\n",
        "    face_helper = FaceRestoreHelper(\n",
        "        args.upscale,\n",
        "        face_size=512,\n",
        "        crop_ratio=(1, 1),\n",
        "        det_model = args.detection_model,\n",
        "        save_ext='png',\n",
        "        use_parse=True,\n",
        "        device=device)\n",
        "\n",
        "    # -------------------- start to processing ---------------------\n",
        "    for i, img_path in enumerate(input_img_list):\n",
        "        # clean all the intermediate results to process the next image\n",
        "        face_helper.clean_all()\n",
        "\n",
        "        if isinstance(img_path, str):\n",
        "            img_name = os.path.basename(img_path)\n",
        "            basename, ext = os.path.splitext(img_name)\n",
        "            print(f'[{i+1}/{test_img_num}] Processing: {img_name}')\n",
        "            img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n",
        "        else: # for video processing\n",
        "            basename = str(i).zfill(6)\n",
        "            img_name = f'{video_name}_{basename}' if input_video else basename\n",
        "            print(f'[{i+1}/{test_img_num}] Processing: {img_name}')\n",
        "            img = img_path\n",
        "\n",
        "        if args.has_aligned:\n",
        "            # the input faces are already cropped and aligned\n",
        "            img = cv2.resize(img, (512, 512), interpolation=cv2.INTER_LINEAR)\n",
        "            face_helper.is_gray = is_gray(img, threshold=10)\n",
        "            if face_helper.is_gray:\n",
        "                print('Grayscale input: True')\n",
        "            face_helper.cropped_faces = [img]\n",
        "        else:\n",
        "            face_helper.read_image(img)\n",
        "            # get face landmarks for each face\n",
        "            num_det_faces = face_helper.get_face_landmarks_5(\n",
        "                only_center_face=args.only_center_face, resize=640, eye_dist_threshold=5)\n",
        "            print(f'\\tdetect {num_det_faces} faces')\n",
        "            # align and warp each face\n",
        "            face_helper.align_warp_face()\n",
        "\n",
        "        # face restoration for each cropped face\n",
        "        for idx, cropped_face in enumerate(face_helper.cropped_faces):\n",
        "            # prepare data\n",
        "            cropped_face_t = img2tensor(cropped_face / 255., bgr2rgb=True, float32=True)\n",
        "            normalize(cropped_face_t, (0.5, 0.5, 0.5), (0.5, 0.5, 0.5), inplace=True)\n",
        "            cropped_face_t = cropped_face_t.unsqueeze(0).to(device)\n",
        "\n",
        "            try:\n",
        "                with torch.no_grad():\n",
        "                    output = net(cropped_face_t, w=w, adain=True)[0]\n",
        "                    restored_face = tensor2img(output, rgb2bgr=True, min_max=(-1, 1))\n",
        "                del output\n",
        "                torch.cuda.empty_cache()\n",
        "            except Exception as error:\n",
        "                print(f'\\tFailed inference for CodeFormer: {error}')\n",
        "                restored_face = tensor2img(cropped_face_t, rgb2bgr=True, min_max=(-1, 1))\n",
        "\n",
        "            restored_face = restored_face.astype('uint8')\n",
        "            face_helper.add_restored_face(restored_face, cropped_face)\n",
        "\n",
        "        # paste_back\n",
        "        if not args.has_aligned:\n",
        "            # upsample the background\n",
        "            if bg_upsampler is not None:\n",
        "                # Now only support RealESRGAN for upsampling background\n",
        "                bg_img = bg_upsampler.enhance(img, outscale=args.upscale)[0]\n",
        "            else:\n",
        "                bg_img = None\n",
        "            face_helper.get_inverse_affine(None)\n",
        "            # paste each restored face to the input image\n",
        "            if args.face_upsample and face_upsampler is not None:\n",
        "                restored_img = face_helper.paste_faces_to_input_image(upsample_img=bg_img, draw_box=args.draw_box, face_upsampler=face_upsampler)\n",
        "            else:\n",
        "                restored_img = face_helper.paste_faces_to_input_image(upsample_img=bg_img, draw_box=args.draw_box)\n",
        "\n",
        "        # save faces\n",
        "        for idx, (cropped_face, restored_face) in enumerate(zip(face_helper.cropped_faces, face_helper.restored_faces)):\n",
        "            # save cropped face\n",
        "            if not args.has_aligned:\n",
        "                save_crop_path = os.path.join(result_root, 'cropped_faces', f'{basename}_{idx:02d}.png')\n",
        "                imwrite(cropped_face, save_crop_path)\n",
        "            # save restored face\n",
        "            if args.has_aligned:\n",
        "                save_face_name = f'{basename}.png'\n",
        "            else:\n",
        "                save_face_name = f'{basename}_{idx:02d}.png'\n",
        "            if args.suffix is not None:\n",
        "                save_face_name = f'{save_face_name[:-4]}_{args.suffix}.png'\n",
        "            save_restore_path = os.path.join(result_root, 'restored_faces', save_face_name)\n",
        "            imwrite(restored_face, save_restore_path)\n",
        "\n",
        "        # save restored img\n",
        "        if not args.has_aligned and restored_img is not None:\n",
        "            if args.suffix is not None:\n",
        "                basename = f'{basename}_{args.suffix}'\n",
        "            save_restore_path = os.path.join(result_root, 'final_results', f'{basename}.png')\n",
        "            imwrite(restored_img, save_restore_path)\n",
        "\n",
        "    # save enhanced video\n",
        "    if input_video:\n",
        "        print('Video Saving...')\n",
        "        # load images\n",
        "        video_frames = []\n",
        "        img_list = sorted(glob.glob(os.path.join(result_root, 'final_results', '*.[jp][pn]g')))\n",
        "        for img_path in img_list:\n",
        "            img = cv2.imread(img_path)\n",
        "            video_frames.append(img)\n",
        "        # write images to video\n",
        "        height, width = video_frames[0].shape[:2]\n",
        "        if args.suffix is not None:\n",
        "            video_name = f'{video_name}_{args.suffix}.png'\n",
        "        save_restore_path = os.path.join(result_root, f'{video_name}.mp4')\n",
        "        vidwriter = VideoWriter(save_restore_path, height, width, fps, audio)\n",
        "\n",
        "        for f in video_frames:\n",
        "            vidwriter.write_frame(f)\n",
        "        vidwriter.close()\n",
        "\n",
        "    print(f'\\nAll results are saved in {result_root}')\n"
      ],
      "metadata": {
        "id": "ibbmKAaIzlm3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "e9CGuBtQm4fn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Required Libraries\n",
        "import os\n",
        "import shutil\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import files\n",
        "\n",
        "# Visualization Function\n",
        "def display(img1, img2):\n",
        "    fig = plt.figure(figsize=(25, 10))\n",
        "    ax1 = fig.add_subplot(1, 2, 1)\n",
        "    plt.title('Input', fontsize=16)\n",
        "    ax1.axis('off')\n",
        "    ax2 = fig.add_subplot(1, 2, 2)\n",
        "    plt.title('CodeFormer', fontsize=16)\n",
        "    ax2.axis('off')\n",
        "    ax1.imshow(img1)\n",
        "    ax2.imshow(img2)\n",
        "\n",
        "def imread(img_path):\n",
        "    img = cv2.imread(img_path)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Image file not found at {img_path}\")\n",
        "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    return img\n",
        "\n",
        "# Paths\n",
        "input_folder = '/content/input'\n",
        "output_folder = '/content/output_bots'\n",
        "codeformer_path = '/content/CodeFormer'\n",
        "\n",
        "# Clean up previous runs\n",
        "if os.path.isdir(input_folder):\n",
        "    shutil.rmtree(input_folder)\n",
        "os.mkdir(input_folder)\n",
        "if os.path.exists(output_folder):\n",
        "    shutil.rmtree(output_folder)\n",
        "os.mkdir(output_folder)\n",
        "\n",
        "# Image Upload\n",
        "def image_from_device():\n",
        "    uploaded = files.upload()\n",
        "    for filename in uploaded.keys():\n",
        "        dst_path = os.path.join(input_folder, filename)\n",
        "        print(f'Move {filename} to {dst_path}')\n",
        "        shutil.move(filename, dst_path)\n",
        "\n",
        "# Execute Image Upload\n",
        "image_from_device()\n",
        "clear_output()\n",
        "file_count = len(os.listdir(input_folder))\n",
        "if file_count >= 1:\n",
        "    print(\"Run next cell\")\n",
        "else:\n",
        "    print(\"Please upload an image.\")\n",
        "\n",
        "# Inference the uploaded images\n",
        "os.chdir(codeformer_path)\n",
        "\n",
        "CODEFORMER_FIDELITY = 0.7\n",
        "BACKGROUND_ENHANCE = True\n",
        "FACE_UPSAMPLE = True\n",
        "\n",
        "# Running the inference and saving outputs in specified output folder\n",
        "command = f'python inference_codeformer.py -w {CODEFORMER_FIDELITY} --input_path {input_folder} --output_path {output_folder}'\n",
        "if BACKGROUND_ENHANCE:\n",
        "    command += ' --bg_upsampler realesrgan'\n",
        "if FACE_UPSAMPLE:\n",
        "    command += ' --face_upsample'\n",
        "\n",
        "os.system(command)\n",
        "\n",
        "# Debugging information to verify the output\n",
        "print(f\"All results are saved in {output_folder}\")\n",
        "output_files = os.listdir(output_folder)\n",
        "print(f\"Files in output folder: {output_files}\")\n",
        "\n",
        "# Check if output folder contains any images\n",
        "final_results_folder = os.path.join(output_folder, 'final_results')\n",
        "if not os.path.exists(final_results_folder):\n",
        "    raise FileNotFoundError(f\"No final_results folder found in {output_folder}\")\n",
        "\n",
        "final_results_files = os.listdir(final_results_folder)\n",
        "if not final_results_files:\n",
        "    raise FileNotFoundError(f\"No output images found in {final_results_folder}\")\n",
        "\n",
        "# Display Results\n",
        "input_image_path = os.path.join(input_folder, os.listdir(input_folder)[0])\n",
        "output_image_path = os.path.join(final_results_folder, final_results_files[0])\n",
        "\n",
        "print(f\"Input image path: {input_image_path}\")\n",
        "print(f\"Output image path: {output_image_path}\")\n",
        "\n",
        "input_image = imread(input_image_path)\n",
        "output_image = imread(output_image_path)\n",
        "display(input_image, output_image)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Hn0wIGV2D5uc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}